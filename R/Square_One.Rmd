---
title: "Square_One"
author: "Kyle Chezik"
date: "5/18/2018"
output: html_document
---

```{r StartUp Stan}
#Get necessary libraries.
library(tidyverse); library(rstan)
#Initiate cores and make sure unchanged models are not recompiled.
options(mc.cores = parallel::detectCores(), auto_write = TRUE)
```

##Data Simulation and Parameter Estimation Functions

These functions create simulated data and offer tools to estimate parameter priors.

```{r Generative Functions}
#Logistic curve relating air and water temperature (i.e., Global Model).
alpha_est = function(){
  #k = rnorm(1,.15,.01) #Rate of change between max and min mean t.
  k = .15
  #b = rnorm(1,0,.01) #Minimum mean temperature.
  b = 0
  #alpha_max = rnorm(1,27,.1)-b #Maximum mean temperature minus the minimum mean temperature.
  alpha_max = 27
  #m = rnorm(1,16,.1) #Air temperature that is the mid point between alpha_max and b.
  m = 16
  data.frame(alpha_max, k, b, m)
}
# Create annual temperature curves.
create = function(A, AR, s_t, meanT, years = 1, tao, df = 3, sp_n=NA, snow=NA, source = "air"){
  # Number of samples.
  N = years*365 * 24
  # Generic season cycle.
  d_cycle = cos((years*2)*pi*1:N/N + tao*pi)
  #Variance by season.
  sd = 1/exp(abs(diff(d_cycle))); sd = (scale(sd)+2)/s_t; sd = c(sd[,1], sd[1,1])
  # Daily cycle by hour.
  h_cycle = sd*(cos((years*2)*pi*1:N/24 + tao*pi))
  # Seasonally adjusted AR1 correlated noise.
  noise = arima.sim(model = list(ar = AR), n = N, 
                    rand.gen = function(n, ...) rt(n, df = df))
  #Possible snow effect for water.
  if(source == "water"){
    #Align snow effect with adjusted observation period.
    i = ceiling((365*24 - sp_n) - abs(182.5*tao)); sn = cos(2*pi*1:sp_n/sp_n)-1; r = (N/years)-i-length(sn)
    #Snow effect
    snow_adj = rep(c(rep(0,i),sn,rep(0,r)),years) * snow 
  }
  #Return combined data.
  if(source == "air") dat = (d_cycle * A + meanT) + h_cycle + noise*sd
  if(source == "water") dat = (d_cycle * A + meanT + snow_adj) + h_cycle + noise*sd
  dat
}
# Extract chunks of data randomly within a year.
period = function(df, col){
  library(tidyverse);library(lubridate)
  init = sample_n(df, 1)$time
  fin = init  + ddays(round(psych::logistic(rnorm(n = 1, mean = psych::logit(yday(init)/365), sd = 1))*365))
  names(df)[[col]] = "temperature"
  filter(df, time >= init, time <= fin) %>% select(time, temperature)
}
# Eliminate data from the dataframe that has been used so there isn't overlap.
reduce = function(df, sub_df){
  df[!(df$time %in% sub_df$time),]
}
# This function is a wrapper that uses samp_per(), create(), ground(), period() and reduce() to generate random data over the course of a year that is made up of three different functions.
# This function is a wrapper that uses samp_per(), create(), ground(), period() and reduce() to generate random data over the course of a year that is made up of three different functions.
generate = function(air_ends = F, air = F, years = 1, randomize = c(T,T), global){
  library(tidyverse); library(lubridate)
  
  # Sample location latitude.
  latitude = rnorm(1,50,4) #45 to 60ºN with a mean of 50.
  
  #Air parameters. http://www-das.uwyo.edu/~geerts/cwx/notes/chap16/geo_clim.html
  air_A = rnorm(1, .45*latitude, latitude*.02)/2 # Temperature range is latitude dependant.
  air_AR = rbeta(n = 1, shape1 = 500, shape2 = 25)
  air_meanT = 27-(latitude-16)*.57 + rnorm(1,0,.25)
 #.65 
  #Water parameters.
  water_meanT = rnorm(1,(global$alpha_max/(1+exp(-global$k*(air_meanT-global$m))))+global$b,0.1)
  
  #relationship between W_mean and W_A.
  alpha_inf = 13.5
  if(water_meanT<alpha_inf) water_A = water_meanT + rnorm(1, 0, .1)
  else water_A = (alpha_inf - (water_meanT-alpha_inf)) + rnorm(1, 0, .1)
  water_A = if_else(water_A>air_A, air_A-0.01, water_A)
  
  water_AR = rbeta(n = 1, shape1 = 400, shape2 = 20)
  
  # Period length and strength of snow effect.
  sp_n = round(rnorm(1,182,2),0)*24; snow = rbeta(1,1,1)
  
  #Seasonal Period Parameter
  tao = rbeta(1,1,1) # Randomize sampling period.
  
  #Create Data.
  df = data.frame(
    air= create(A=air_A, AR=air_AR, s_t=15, meanT=air_meanT, years=years, tao=tao+0.035, df = 7),
    water= create(A=water_A, AR=water_AR, s_t=20, meanT=water_meanT, years=years, tao=tao-0.035, df=10,
                  sp_n = sp_n, snow = snow, source = "water"),
  
    # Add a time component so the data can be sampled.
    time = seq(from = ymd_h("2000-07-15 00") + ddays(round(182.5*tao)),
               by = "hour", length.out = years*365*24))
  
  #Add air to the begining and end.
  if(randomize[1] == T & air_ends == F) {
    ans = sample(x = c(0,1), size = 1, prob = c(.1,.9))
    if(ans == 1) air_ends = T
    ans = 0
  }
  if(air_ends == T){
    ends = filter(df,time <= floor_date(min(time), unit = "day")+dhours(23) | time >= floor_date(max(time))-dhours(23)) %>% 
      select(time, air) %>% 
      rename(., temperature = air) %>% 
      mutate(source = "air")
    df = reduce(df, ends)
  }
  
  #Select air error region.
  if(randomize[2] == T & air == F) {
    ans = sample(x = c(0,1), size = 1, prob = c(.3,.7))
    if(ans == 1) air = T
    ans = 0
  }
  if(air == T){
    airT = period(df, 1) %>%
      mutate(source = "air")
    df = reduce(df, airT)
  }
  
  #Fill remaining time period with water data.
  water = df %>% select(time, water) %>% rename(., temperature = water) %>% 
    mutate(source = "water")
  
  #Combine and return a mixed dataset.
  fin = water
  if(air_ends == T) fin = suppressWarnings(bind_rows(ends, fin))
  if(air == T) fin = suppressWarnings(bind_rows(fin, airT))
  fin = arrange(fin, time)
  
  cfs = data.frame(latitude, air_tao = tao+0.035, water_tao = tao-0.035,
                   alpha_max = global$alpha_max, 
                   k = global$k, b = global$b, 
                   aw_infl = global$m,
                   air_AR,water_AR,
                   air_A, water_A,
                   air_meanT, water_meanT,
                   sp_n = sp_n/24, snow)
  list(dat = fin, coefs = cfs)
}

multi_site = function(n = 1, years = 1, air_ends = F, air = F, randomize = c(T,T)){
  #Create list to be filled.
  ret = list(dat = NULL, coefs = NULL)
  #Generate hourly data `n` number of sites.
  for(i in 1:n){
    #Gather global model coefficients.
    global = alpha_est()
    #Generate hourly data made from air and water sources.
    df = generate(air = air, air_ends = air_ends, 
                  randomize = randomize, years = years, global = global) 
    #Add site number and period in annual cycle.
    df$dat = mutate(df$dat, site = i, 
                    d_cycle = yday(time - days(x=yday(time[1])-1)),
                    n = n_init(time))
    df$coefs = mutate(df$coefs, site = i)
    #Bind data and coefs into list.
    ret$dat = suppressWarnings(bind_rows(ret$dat, df$dat))
    ret$coefs = suppressWarnings(bind_rows(ret$coefs, df$coefs))
  }
  #Rename lists
  dat = list("hourly" = ret$dat, "coefs" = ret$coefs)
  #Daily summary
  ret = ret$dat %>% mutate(time = lubridate::floor_date(time, unit = "day")) %>% 
    group_by(site, source, time) %>%
    summarize(temperature = mean(temperature)) %>% 
    arrange(site, time)
  #Remove duplicate days due to rounding errors.
  dups = ret %>% group_by(site,time) %>% summarise(c = n()) %>% filter(c>1)
  del = vector(mode = "numeric",length = length(dups)/2); c=1
  if(nrow(dups)>0){
    for (i in 1:nrow(dups)){
      rows = which(ret$time==dups[i,"time"][[1]] & ret$site == dups[i,"site"][[1]])
      del[c] = sample(rows,1)
      c=c+1
    }
  dat$daily = ret[-del,]
  } else dat$daily = ret
  
  #Add cycle length (`n`) and point in cycle (`d`).
  dat$daily = dat$daily %>% group_by(site) %>% 
    mutate(year = lubridate::year(time), d = yday(time - days(x=yday(time[1])-1))) %>% 
    group_by(site, year) %>% mutate(n = n_init(time))
  
  #Add tau prior estimate and determine how many points are in an annual cycle.
  dat$coefs = dat$daily %>% group_by(site) %>%
    summarise(tau_approx = tau_init(time = time)) %>% 
    left_join(dat$coefs,., by = "site")
  dat
}


#Determine values to constraine the search space.

#Estimate tao via the data assuming a northern hemisphere cycle.
tau_init = function(time){
  library(lubridate)
  ref = data.frame(date = yday(seq(from = ymd("2000-07-15"), by = "day", length.out = 366)),
                 tao = seq(from = 0 , to = 2, length.out = 366))
  ref[ref$date == yday(min(time)),"tao"]
}
#Provide the number of observations in a year. Will determine the number of periods.
n_init = function(time){
  library(lubridate)
  if(length(time) == 1) cc = 365
  else {
    dur = data.frame(table(as.numeric(as.duration(time[2:length(time)]-time[1:(length(time)-1)])))) %>% 
      arrange(desc(Freq)) %>% as.tbl(.)
    dur = as.numeric(as.character(dur[[1]]))[1]
    cc = as.numeric(dyears(1)/dur[1])
  }
  if(leap_year(year(time[1]))) cc = cc + 1
  else cc = cc
  cc
}
#Build initial conditions for different numbers of chains.
create_inits = function(K = 2, A_ij = c(.9,.1,.1,.9), air_A, air_mean, chains = 1){
  #Create single chain list
  A_ij = diag(K); A_ij = if_else(A_ij ==1, .9, .1/(K-1))
  init = list(A_ij = matrix(A_ij, nrow = K, ncol = K),
              b_alpha_w = 2, m_alpha_w = .5,
              A = matrix(data = c(air_mean,air_A), nrow=length(air_A) , ncol=2),
              alpha_w = if_else(air_mean>0,air_mean,2))
  init$A[,1] = if_else(init$alpha_w<13.5, init$alpha_w, (27-init$alpha_w))
  init$A[,1] = if_else(init$A[,1]>=init$A[,2], init$A[,2]-.5, init$A[,1])
  #Replicate single list over n chains
  inits = list()
  for(i in 1:chains){
    inits[[i]] = init
  }
  #return inits
  inits
}

stream_snow = function(n, d, tau){
  d_low = (n/2)-(tau * (n/2))
  d_high = n-(tau * (n/2))
  c(cos(2*pi*(d-d_low[d>d_low & d<d_high])/(n/2))-1,
    rep(0,sum(d<=d_low | d>=d_high)))
}
air_snow = function(n, d, tau){
  d_low = (n/2)-(tau * (n/2))
  d_high = n-(tau * (n/2))
  
  c(cos(2*pi*(d-d_low[d>d_low & d<d_high])/(n/2) + 1.5*pi),
    rep(0,sum(d<=d_low | d>=d_high)))
}
```

## Plot Model Results

These functions offer plotting capabilities after running a Hidden Markov Model.

```{r Plot Probabilities}
prob_plot = function(mod, date, temperature, air = NULL, smooth = T, err_perc = NULL,
                     bc_climate = list(air_mean = NA, air_A = NA)){
  
  #Build dataframe
  if(is.null(err_perc)) df = as.tibble(data.frame(date,temperature)) %>% arrange(date)
  else df = as.tibble(data.frame(date,temperature,source = err_perc)) %>% arrange(date) 
  #Add d and n values.
  df = df %>% mutate(year = lubridate::year(date), d = yday(date - days(x=yday(date[1])-1))) %>% 
    group_by(year) %>% mutate(n = n_init(date))
  
  #Coefficients
  cf = rstan::extract(mod, pars = c("alpha_w","A","tau_est","snow_w"))

  #Produce full bayesian probabilities
  fit_w = data.frame(t(sapply(c(1:nrow(df)), function(x){
    quantile(cf$alpha_w + cf$A * cos(2*pi*df[x,"d"][[1]]/df[x,"n"][[1]] + cf$tau_est[,1]*pi) +
               stream_snow(df[x,"n"][[1]], df[x,"d"][[1]], cf$tau_est[,1]) * cf$snow_w,
             probs = c(0.025,.25,0.5,.75,.975))
  }))) %>% 
    rename(w_lower = X2.5., w_lower_mid = X25., w_fit = X50., w_upper_mid = X75., w_upper = X97.5.)
  
  fit_a = data.frame(t(sapply(c(1:nrow(df)), function(x){
    quantile(bc_climate$air_mean + bc_climate$air_A * cos(2*pi*df[x,"d"][[1]]/df[x,"n"][[1]] + cf$tau_est[,2]*pi),
             probs = c(0.025,.25,0.5,.75,.975))
  }))) %>% 
    rename(a_lower = X2.5., a_lower_mid = X25., a_fit = X50., a_upper_mid = X75., a_upper = X97.5.)
  
  #Extract log-/probability estimates and their upper and lower quartiles
  if(smooth == T) xi_est = rstan::extract(mod,"gamma")$gamma
  else xi_est = rstan::extract(mod,"alpha_tk")$alpha_tk
  
  water = data.frame(t(sapply(c(1:nrow(df)),function(x){
    quantile(xi_est[,x,1],probs = c(0.025,.25,0.5,.75,.975))
  }))) %>% 
        rename(p_lower = X2.5., p_lower_mid = X25., p_prob = X50., p_upper_mid = X75., p_upper = X97.5.)
  
  #Combine fit and probabilities with data and add error columns
  df = df %>% bind_cols(.,water,fit_w,fit_a) %>% 
    mutate(est_source = if_else(p_prob>.5,"water","air"))
  if(!is.null(err_perc)){
    df = df %>% mutate(err = if_else(source == est_source, 1, 19))
    percent_error = round((1-sum(df$source==df$est_source)/nrow(df))*100)
  }
  
  #Build Plots
  
  #Probability plot
  p1p = ggplot(df) + 
    geom_line(aes(date, p_prob), size = .3, linetype = 2) +
    geom_ribbon(aes(date, ymin = p_lower, ymax = p_upper), alpha =.3, fill = "#5b0982") +
    scale_x_datetime(date_breaks = "3 month", date_labels = "%b") +
    ggthemes::theme_tufte() +
    theme(axis.text = element_text(size = 8),axis.title = element_text(size = 9)) +
    labs(x = "", y = "% Prob. Water")
  
  #Raw/Probability
  p1 = ggplot(df) + 
    geom_line(aes(date, temperature), size = .2) +
    geom_point(aes(date, temperature, col = p_prob), size = .3, shape = 19) +
    geom_hline(yintercept = 0, linetype = 2, size = .2) +
    scale_x_datetime(date_breaks = "3 month", date_labels = "%b") +
    viridis::scale_color_viridis(direction = -1) +
    ggthemes::theme_tufte() +
    theme(legend.position = "top", legend.direction = "horizontal",
          axis.line.x = element_line(color="black", size = .2),
          legend.key.width = unit(1,"cm"),
          legend.key.height = unit(.20,"cm"),
          strip.text = element_text(size=8), axis.text = element_text(size = 8),
          axis.title = element_text(size = 9), legend.title = element_text(size = 8),
          legend.text = element_text(size = 8)) +
    labs(color ="Probability Water", x = "", y = expression("Temperature ("*degree*"C)")) +
    guides(colour = guide_colourbar(title.position="top"))
  
  df$date = lubridate::ymd(df$date)
  #Best Fit
  p1f = ggplot(df, aes(date,temperature)) 
  if(!is.null(air)){
    p1f = p1f + geom_point(data = air, aes(date, mean_temp_c),
                           color = "red", shape = 1, size = .3, alpha = .2) +
      geom_line(aes(date, a_fit), size = .3) +
      geom_ribbon(aes(date, ymin = a_lower, ymax = a_upper), 
                alpha = .1, fill = "#ffc021")
  }
  if(!is.null(err_perc)){
    p1f = p1f + geom_rug(data = filter(df, err == 19), aes(date, temperature), sides = "b")+
      ggtitle(paste(percent_error,"% error", sep = ""))
  }
  
  p1f = p1f + geom_point(aes(color = est_source), size = 0.3, shape = 19) +
    geom_line(aes(date, w_fit), size = .3) +
    geom_ribbon(aes(date, ymin = w_lower, ymax = w_upper), 
                alpha = .1, fill = "#5b0982") +
    scale_x_date(date_breaks = "3 month", date_labels = "%b") +
    scale_color_manual(values = c("water" = "#2b6aff", "air" = "#ffc021", "ground" = "#45062e")) +
    geom_hline(yintercept = 0, size = .2, linetype = 3) +
    labs(color = "Estimated Thermal Source", x = "Month", y = expression("Temperature ("*degree*"C)")) +
    ggthemes::theme_tufte() +
    theme(legend.direction = "horizontal", legend.position = "top",
      axis.line.x = element_line(color = "black", size = .2),
      strip.text = element_text(size=8), axis.text = element_text(size = 8), 
      axis.title = element_text(size = 9), legend.title = element_text(size = 8),
      legend.text = element_text(size = 8), plot.title = element_text(size = 9)) +
    guides(colour = guide_legend(title.position="top"))
  
  p = gridExtra::grid.arrange(p1p, p1, p1f, layout_matrix = matrix(data = c(1,2,2,3,3), nrow = 5, ncol = 1))
  ggsave(filename = "probPlot.pdf", path = "~/Documents/rTDataScrub/images", plot = p, width = 4.25, height = 6.5, units = "in", device = "pdf")
  #list(p1p,p1,p1f)
}
```

## Seasonal Cycle Temperature Model

We are using a seasonal cycle model...
   `y[t] = alpha + A*cos(Y*2*pi*w + tau*pi) + sigma_t`, 
      `sigma_t ~ (cos(2*pi*w*t + tau)+2)*sigma`,
where `alpha` represents the vertical adjustment (i.e, mean) of the cosine curve and `A` refers to its expansion (i.e., amplitude). `Y` controls the number of cycles (i.e, years) the data contain and `w` is the frequency of the cycle and equals `t`/`N` where `t` is the current time point and `N` is the total number of time points in one cycle or in this case one year. `tau` controls where in the seasonal temperature cycle we begin observing data. The errors are seasonally adjusted so they are largest during winter and summer and least in the spring and fall. We created this model similar to that on page 67 of **Time Series Analysis and Its Applications** by Robert H. Shumway and David S. Stoffer.

Now we'll recapture `alpha`, `A`, `tau`, `rho` and `sigma`.

```{r Recapture Simulated Air & Water}
#create data
df = multi_site(n = 1, years = 1, air_ends = F, air = F, randomize = c(F,F))

#Compile and run model.
compile = stan_model("./stan/01_AW_sim.stan")
mod = sampling(compile, data = list(N = length(df$daily$temperature), y = df$daily$temperature),
                warmup = 300, iter = 800, chains = 4)

#Coefficients
cf = broom::tidy(mod, pars = c("alpha","A","tau","sigma"), "mean") %>%
  select(-std.error) %>% spread(term,estimate)
df$daily = df$daily %>% mutate(y_hat = cf$alpha + cf$A*cos(2*pi*d/365 + cf$tau*pi),
                    sd = qt(p = .95, df = 3)*cf$sigma)

# Plot temperature by site.
ggplot() +
  geom_ribbon(data = df$daily, aes(time, ymin = y_hat - sd, ymax = y_hat + sd), fill = "red", alpha = 0.1) +
  geom_point(data = df$daily, aes(time, temperature), color = "red", size = .8) + 
  geom_line(data = df$daily, aes(time, temperature), size = .2) + 
  geom_line(data = df$daily, aes(time, y_hat), color = "blue") + 
  geom_hline(yintercept = 0) +
  facet_wrap(~site) + ggthemes::theme_tufte()
```

In the water and air temperature case we can easily recapture the coefficients. Now we'll apply this model to some known water and air temperature data to see if they fit the data well.

```{r Real Temperature Fit}
#Real data.
dat = read_rds(path = "./Data/test_labeled.rds")
air = dat %>% filter(source == "air", !is.na(temperature)) %>% arrange(date)
water = dat %>% filter(source == "water", !is.na(temperature)) %>% arrange(date)

#air mod
mod = sampling(compile, data= list(N = length(air$temperature), y = air$temperature),
                        warmup = 300, iter = 800, chains = 4)

#Coefficients
cf = broom::tidy(mod, pars = c("alpha","A","tau","sigma"), "mean") %>%
  select(-std.error) %>% spread(term,estimate)

#collect results
air = air %>% mutate(d = c(1:length(temperature)),
                    y_hat = cf$alpha + cf$A*cos(2*pi*d/length(temperature)+ cf$tau*pi),
                    sd = qt(p = .95, df = 3)*cf$sigma)

#water mod
mod = sampling(compile, data= list(N = length(water$temperature), y = water$temperature),
               warmup = 300, iter = 800, chains = 4)
               
#Coefficients
cf = broom::tidy(mod, pars = c("alpha","A","tau","sigma"), "mean") %>%
  select(-std.error) %>% spread(term,estimate)

#collect results
water = water %>% mutate(d = c(1:length(temperature)),
                    y_hat = cf$alpha + cf$A*cos(2*pi*d/length(temperature) + cf$tau*pi),
                    sd = qt(p = .95, df = 3)*cf$sigma)                       

#plot results
ggplot() +
  geom_ribbon(data = air, aes(date, ymin = y_hat - sd, ymax = y_hat + sd), fill = "red", alpha = 0.1) +
  geom_point(data = air, aes(date, temperature), color = "red", size = .8) + 
  geom_ribbon(data = water, aes(date, ymin = y_hat - sd, ymax = y_hat + sd), fill = "blue", alpha = 0.4) +
  geom_point(data = water, aes(date, temperature), color = "blue", size = .8) + 
  geom_line(data = air, aes(date, y_hat), color = "black") + 
  geom_line(data = water, aes(date, y_hat), color = "black") + 
  geom_hline(yintercept = 0) +
  ggthemes::theme_tufte()
```

The model fits the real water and air temperature data well and captures the major differences between the two temperature sources. This is encouraging that the models, though the same, may have such different parameter values they will be seperable in the HMM. One noteable difference is that water temperature tends to increase slowly in the spring due to snow melt resulting in hysteresis in the temperature curve. 

## HMM Model

Now we need to combine the air and water temperature data and build a Hidden Markov Model that pulls them apart.

```{r Recapture Simulated Multi-Sources w/HMM}
df = multi_site(n = 1, years = 1, air_ends = T, air = T, randomize = c(F,F))
inits = create_inits(air_A = df$coefs$air_A, air_mean = df$coefs$air_meanT, chains = 4)

#Compile and run model.
compile = stan_model("./stan/02_HMM.stan")
mod = sampling(compile, data= list(N = nrow(df$daily), K = 2,
                                  y = round(df$daily$temperature,2),
                                  tau = tau_init(time = df$daily$time), 
                                  n = rep(n_init(time = df$daily$time),nrow(df$daily)),
                                  d = df$daily$d,
                                  air_A = df$coefs$air_A,
                                  air_mean = df$coefs$air_meanT,
                                  water_A = inits[[1]]$A,
                                  water_mean = inits[[1]]$alpha_w),
               pars = c("alpha_w","A","tau_est","snow_w","sigma","alpha_tk","gamma"),
               init = inits, warmup = 1000, iter = 2000, chains = 4, thin = 3,
               control = list(adapt_delta = .9, max_treedepth = 12), save_warmup = F)

#Plot
prob_plot(mod, df$daily$time, df$daily$temperature, smooth = F, err_perc = df$daily$source,
          bc_climate = list(air_mean = df$coefs$water_meanT, air_A = df$coefs$air_A))
```

I did not include auto-regressive or moving average terms as they are not condusive to HMMs in this context. The parameter controling the influence of the previous data point(s) is too general making it really easy for chains to find local optimums. In other words, these parameters are too flexible and don't constrain the models enough, resulting in a lot of overlap. To account for hysteresis in the water curve due to snow melt I applied a downward pull during the spring period by introducing a negative bound cosine curve and snow coefficient to either dampen or amplify the spring snow effect. This seems to capture the hysteresis without allowing the model too much flexibility.

After giving the HMM some guidance using fairly general initial parameters, we get very good accordance with the known data types (>99%).

Now I would like to apply this model to my real data and just see if it can capture the same relationships when the data may or may not follow a cosine curve perfectly.

```{r HMM on Real Data}
#Read in ClimateBC air temperature approximations
df_inits = read_rds("./Data/thompson_air_inits.rds") %>% 
  filter(site == 49) %>% summarise(air_mean = mean(air_mean), air_A = mean(air_A))
#Read in observation data and summarize.
df_T = read_rds("./Data/thompson_water.rds") %>% filter(site == 49) %>%
  mutate(day = lubridate::floor_date(date, unit = "day"), 
         doy = lubridate::yday(date),
         year = lubridate::year(date)) %>%
  group_by(year, day, doy) %>% summarise(temperature = mean(temperature)) %>% ungroup(.) %>% 
  mutate(d = lubridate::yday(day - lubridate::days(x=lubridate::yday(day[1])-1))) %>% group_by(year) %>% 
  mutate(n = n_init(day))
#Create initial values for the model
inits = create_inits(air_A = df_inits$air_A, air_mean = df_inits$air_mean, chains = 4)
#Read in nearest air station.
air = read_rds("./Data/thompson_air.rds") %>% filter(place == "DARFIELD")

#Compile Model
compile = stan_model("./stan/02_HMM.stan")
#Run model.
mod = sampling(compile, data= list(N = nrow(df_T), K = 2,
                                   y = round(df_T$temperature,2),
                                   tau = tau_init(time = df_T$day), 
                                   n = df_T$n,
                                   d = df_T$d,
                                   air_A = df_inits$air_A,
                                   air_mean = df_inits$air_mean,
                                   water_A = inits[[1]]$A,
                                   water_mean = inits[[1]]$alpha_w),
               pars = c("alpha_w","A","tau_est","snow_w","sigma","alpha_tk","gamma"),
               init = inits, warmup = 1000, iter = 2000, chains = 4, thin = 3,
               control = list(adapt_delta = .9, max_treedepth = 12), save_warmup = F)

#Plot
prob_plot(mod, df_T$day, df_T$temperature, air = air, smooth = F,
          bc_climate = list(air_mean = df_inits$air_mean, air_A = df_inits$air_A))
```

In the real data, if we don't provide air mean and amplitude estimates the model appears to split the water temperature data in two, thereby sharing the same results with only marginal differences. I suspect this could be a problem when a site has no air temperature data to fit. By estimating the amplitutde and mean annual air temperature at a site via the BC Climate module and lat./long. information, we can guarentee one model to be air temperature and the other water. We should set the priors for these values rather narrow to ensure they can only be moved by a fair bit of evidence to the contrary. After fitting the model where the vertical adjustement and amplitude of the air temperature model are clearly defined we get the temperature models fitting the data correctly and even capture the single air temperature values at the beginning and end of the dataset. 

The below model includes a smoother which increases certainty of estimates with a lot of similar data nearby but this also leads to mislabeleing among more sparse data.

```{r Smoothed HMM}
#Plot
prob_plot(mod, df_T$day, df_T$temperature, air = air, smooth = T,
          bc_climate = list(air_mean = df_inits$air_mean, air_A = df_inits$air_A))
```

## Random Effect Model

Now I will begin playing with hierarchical based models where the data are partially pooled across sites but drawn from a distribution describing the parameter variability among sites.

```{r Random Effect Water Model}
df = multi_site(n = 20, years = 1, air_ends = F, air = F, randomize = c(F,F))
#Compile and run model.
compile = stan_model("./stan/03_water_rand.stan")
mod = sampling(compile, data= list(N = length(df$daily$temperature),
                                           S = length(unique(df$daily$site)),
                                           site = df$daily$site,
                                           y = df$daily$temperature,
                                           d = df$daily$d,
                                           tau = df$coefs$tau_approx, n = df$coefs$n_cycle,
                                           air_mean = df$coefs$air_meanT,
                                           prior_only = 0, # Note this option
                                           pars = c("A", "alpha", "tau_est", "sigma")),
                       iter = 300, chains = 4)

cf = broom::tidy(mod, pars = c("alpha_w","A","tau_est","sigma"), "median") %>%
  select(-std.error) %>% 
  mutate(site = as.numeric(stringr::str_extract_all(string = term, pattern = "\\d+",simplify = T)),
         coef = stringr::str_extract_all(term, "\\w+", simplify = T)[,1]) %>%
  select(-term) %>% spread(data = ., key = coef, value = estimate)

#Mean water temperature fit.
temp = df$daily %>% left_join(.,cf, by = "site") %>% mutate(
  mean = alpha_w+A*cos(2*pi*d/365+tau_est*pi))

#Variance around mean water temperature.
temp = temp %>% mutate(
  upper = mean + qt(p = .95, df = 3)*sigma,
  lower = mean - qt(p = .95, df = 3)*sigma)

#Plot data, mean estimate and error.
ggplot() +
  geom_ribbon(data = temp, aes(x = time, ymin = lower, ymax = upper), fill = "red", alpha = 0.3) +
  geom_point(data = temp, aes(time, temperature),alpha = .5, size = .5, color = "black") + 
  geom_point(data = temp, aes(time, mean), color = "blue", size = .5, alpha = .5) +
  geom_hline(yintercept = 0) +
  facet_wrap(~site) + ggthemes::theme_tufte()

#Global Model Fit
df$coefs %>% select(site, air_meanT, water_meanT) %>% left_join(.,cf) %>% 
  ggplot(data = ., aes(water_meanT, alpha_w)) + geom_point() + geom_abline(slope = 1, intercept = 0)
```

Above we use our global model to describe the relationship between mean air temperature (known) and mean water temperature (unknown). This relationship assumes lotic environments never experience mean annual temperatures below 0ºC. It also assumes that as mean air temperatures rise, mean water temperature lags behind initially until some inflection point where they become essentially the same over the middle range of air temperatures (i.e., ~20ºN to 45ºN). At really hot mean annual air temperatures (27ºC near the equator), water means again lag behind due to ground temperature dampening. By creating this relationship we can leverage known mean air temperatures across sites and draw the mean annual water temperaure towards a global mean thereby resisting local water temperature models over-fitting erroneous data (i.e., air or ground). This relationship also ensures that as we add additional sites, the predictive ability of the model gets stronger but is a bit more prone to error for sites nearing extreme values which include unusually warm and cold sites relative to the mean air temperature. Ultimately, approximating the mean annual air temperature and it's relationship with mean annual water temperature will enhance the ability for the model to discern between air, water and other erroneous data.

In the model above we demonstrate that we can generate simulated data and retrieve those values across multiple sites. We can also demonstrate that fits improve with the number of sites included. This is true even if we limit our sites latitudes between 40 and 60ºN which means that while the global model is not exploring the entire range of data we can still approximate these values pretty well.

## HMM Random Effect Model

Next we need to incorporate the hierarchical model into the HMM model and retrieve simulated data.

```{r Simulation Hierarchical HMM}
#Create data for multiple sites.
df = multi_site(n = 20, years = 1, air_ends = T, air = F, randomize = c(F,T))

#Gather initial values.
inits = create_inits(air_A = df$coefs$air_A, air_mean = df$coefs$air_meanT, chains = 4)

#Compile and run model.
compile = stan_model("./stan/04_HMM_Global.stan")
mod = sampling(compile, data= list(N = length(df$daily$temperature),
                                 S = length(unique(df$daily$site)),
                                 site = df$daily$site,
                                 K = 2,
                                 y = round(df$daily$temperature,2),
                                 d = df$daily$d,
                                 tau = df$coefs$tau_approx,
                                 n = df$daily$n,
                                 air_A = df$coefs$air_A,
                                 air_mean = df$coefs$air_meanT,
                                 water_A = inits[[1]]$A[,1],
                                 water_mean = inits[[1]]$alpha_w,
                                 prior = 1),
               pars = c("alpha_w","A","tau_est","snow_w","sigma",
                        "alpha_tk","gamma",
                        "b_alpha_w","m_alpha_w"),
               init = inits, warmup = 200, iter = 500, chains = 4, thin = 1,
               control = list(adapt_delta = .9, max_treedepth = 12), save_warmup = T)

shinystan::launch_shinystan(mod)


#Coefficients
cf = rstan::extract(mod, pars = c("alpha_w","A","tau_est","snow_w","alpha_tk","gamma"))

#Site alpha and A summary/join with known values and priors
alpha = data.frame(t(apply(cf$alpha_w, 2, `quantile`, probs = c(0.025,.25,0.5,.75,.975)))) %>% mutate(param = "alpha[w]")
A = data.frame(t(apply(cf$A[,,1], 2, `quantile`, probs = c(0.025,.25,0.5,.75,.975)))) %>% mutate(param = "A[w]")
global = df$coefs %>% select(water_meanT, water_A) %>% gather(key = obs_param, value = observed) %>% select(-1)
global = bind_rows(alpha,A) %>% rename(lower = X2.5., lower_mid = X25., fit = X50., upper_mid = X75., upper = X97.5.) %>% bind_cols(.,global) %>% mutate(prior = c(inits[[1]]$alpha_w, inits[[1]]$A[,1]))


p = ggplot(global, aes(observed, fit)) + 
  geom_errorbar(aes(x = observed, ymax=upper, ymin=lower), linetype = 1, size = .1, alpha = .3) +
  geom_errorbar(aes(x = observed, ymax=upper_mid, ymin=lower_mid), linetype = 1, size = .3, alpha = .5) +
  geom_point(col = "#45062e", shape = 19, size = .8) +
  geom_point(aes(observed, prior),shape = 1, col = "#2b6aff", size = 1) +
  geom_abline(intercept = 0, slope = 1, linetype = 2, size = .3) +
  ggthemes::theme_tufte() +
  theme(strip.text = element_text(size=10),
        axis.text = element_text(size = 8), 
        axis.title = element_text(size = 9)) +
  labs(x = expression("Simulated Temperature ("*degree*"C)"), 
       y = expression("Estimated Temperature ("*degree*"C)")) +
  facet_wrap(~param, labeller = label_parsed)
ggsave(filename = "Global_Sim.pdf", path = "~/Documents/rTDataScrub/images", plot = p, width = 7.5, height = 3.5, units = "in", device = "pdf")


#ORGANIZE HMM RESULTS

#Mean temperature fit and source probabilities.
fit = df$daily %>% ungroup() %>% mutate(row = 1:length(site)) %>% group_by(site,time) %>% do({
  filter_water = quantile(cf$alpha_tk[,.$row,1], probs = c(0.025,.25,0.5,.75,.975))
  smooth_water = quantile(cf$gamma[,.$row,1], probs = c(0.025,.25,0.5,.75,.975))
  water = cf$alpha_w[,.$site] + cf$A[,.$site,1]*cos(2*pi*.$d/.$n + cf$tau_est[,.$site,1]*pi) + 
    stream_snow(.$n, .$d, cf$tau_est[,.$site,1])*cf$snow_w[,.$site]
  
  air = df$coefs$air_meanT[.$site] + df$coefs$air_A[.$site]*cos(2*pi*.$d/.$n + cf$tau_est[,.$site,2]*pi)
  temp = data.frame(t(c(quantile(water, probs = c(0.025,.25,0.5,.75,.975)),
                 quantile(air, probs = c(0.025,.25,0.5,.75,.975)),
                 filter_water, smooth_water)))
  names(temp) = c("w_lower","w_lower_mid","w_fit","w_upper_mid","w_upper",
                "a_lower","a_lower_mid","a_fit","a_upper_mid","a_upper",
                "fp_lower","fp_lower_mid","fp_fit","fp_upper_mid","fp_upper",
                "sp_lower","sp_lower_mid","sp_fit","sp_upper_mid","sp_upper")
  temp
})

fit = left_join(df$daily, fit)

#Calculate error rates for full range of possible outcomes using both filtered and smoothed probabilities.
perc = seq(.5,.99,.001)
typeI = data.frame(t(sapply(X = perc, FUN = function(t){
  apply(fit[,18:27],2, function(x){sum(x>t & fit[,2] != "water")})
}))) %>% mutate(errorType = "typeI", percent = perc*100)

typeII = data.frame(t(sapply(X = perc, FUN = function(t){
  apply(fit[,18:27],2, function(x){sum(x<t & fit[,2] == "water")})
}))) %>% mutate(errorType = "typeII", percent = perc*100)

error = bind_rows(typeI, typeII)

#Plot error rates
ggplot(error) + 
  #geom_ribbon(aes(percent, ymin = fp_lower, ymax = fp_upper), alpha = .1) +
  #geom_ribbon(aes(percent, ymin = fp_lower_mid, ymax = fp_upper_mid), alpha = .1) +
  geom_line(aes(percent,fp_fit,col=errorType), linetype = 1) + 
  geom_line(aes(percent,sp_fit,col=errorType), linetype = 2) + 
  scale_y_log10() +
  scale_color_manual(values = c("#45062e","#2b6aff"),breaks = c("typeI","typeII"),
                     labels = c("type I","type II")) +
  ggthemes::theme_tufte() +
  theme(legend.direction = "horizontal", legend.position = "top",
        strip.text = element_text(size=10),
        axis.text = element_text(size = 8), 
        legend.title = element_blank()) +
  labs(y = "Number of Errors", 
       x = "Water Certainty Cutoff (%)")
ggsave(filename = "Error_Type.pdf", path = "~/Documents/rTDataScrub/images", plot = p, width = 7.5, height = 3.5, units = "in", device = "pdf")

#Determine the lowest certainty cut-off that minimizes both error types
cutoff = error %>% select(percent, fp_fit, errorType) %>% 
  spread(data = ., key = errorType, value = fp_fit) %>% 
  mutate(dif = abs(typeI-typeII)) %>% 
  filter(dif == min(dif)) %>% 
  .$percent %>% min()/100

#Add errors based on cutoff value.
fit = fit %>% 
  mutate(s_est_source = if_else(sp_fit>=cutoff,"water",if_else(sp_fit<cutoff & sp_fit>.5,"uncertain","air")),
         f_est_source = if_else(fp_fit>=cutoff,"water",if_else(fp_fit<cutoff & fp_fit>.5,"uncertain","air")),
         s_error = if_else(s_est_source == source,1,0),
         f_error = if_else(f_est_source == source,1,0))

#Create error labels for each site.
percent_error = fit %>% group_by(site) %>%
  do({
    n_water = sum(.$source == "water")
    n_AG = sum(.$source != "water")
    
    error1 = round(sum(.$source[.$fp_fit>cutoff]!="water")/n_AG*100)
    error2 = round(sum(.$source[.$fp_fit<cutoff]=="water")/n_water*100)
    data.frame(n_water, n_AG, error1, error2,
      x_pos = min(fit$time),
      y_pos = max(fit$temperature)
    )
  }) %>% 
  mutate(label = paste("type I: ",as.character(error1),"% of ",as.character(n_AG)," -- type II: ",as.character(error2),"% of ",as.character(n_water),sep=""))

labels = c("1" = percent_error$label[1],
           "2" = percent_error$label[2],
           "3" = percent_error$label[3],
           "4" = percent_error$label[4],
           "5" = percent_error$label[5],
           "6" = percent_error$label[6],
           "7" = percent_error$label[7],
           "8" = percent_error$label[8],
           "9" = percent_error$label[9],
           "10" = percent_error$label[10],
           "11" = percent_error$label[11],
           "12" = percent_error$label[12],
           "13" = percent_error$label[13],
           "14" = percent_error$label[14],
           "15" = percent_error$label[15],
           "16" = percent_error$label[16],
           "17" = percent_error$label[17],
           "18" = percent_error$label[18],
           "19" = percent_error$label[19],
           "20" = percent_error$label[20])

#Plot data, mean estimate and error.
p = ggplot(data = fit) +
  geom_line(aes(time, a_fit), size = .3) +
  geom_line(aes(time, w_fit), size = .3) +
  geom_ribbon(aes(x = time, ymin = w_lower, ymax = w_upper), alpha = .3, fill = "#5b0982") +
  geom_ribbon(aes(x = time, ymin = a_lower, ymax = a_upper), alpha = .2, fill = "#7eb795") +
  geom_point(aes(time, temperature, color = fp_fit), size = .5) +
  geom_hline(yintercept = 0, size = .2, linetype = 2) +
  annotate("segment", x=min(fit$time), xend = max(fit$time), y=-Inf, yend=-Inf, size = .2) +
  viridis::scale_color_viridis(direction = -1) +
  ggthemes::theme_tufte() +
  theme(legend.direction = "horizontal", legend.position = "top", 
        legend.key.width = unit(3,"cm") ,
        legend.key.height = unit(.20,"cm"),
        strip.background = element_blank(),
        strip.text.x = element_blank()) +
  scale_x_datetime(date_breaks = "3 month", date_labels = "%b") +
  labs(color ="Probability Water", x = "Month", y = expression("Temperature ("*degree*"C)")) +
  guides(colour = guide_colourbar(title.position="top")) +
  facet_wrap(~site)+
  geom_text(data = percent_error, aes(x = x_pos, y = y_pos, label = site), hjust = "left", size = 2.3)
ggsave(filename = "Probs_Sim.pdf", path = "~/Documents/rTDataScrub/images", plot = p, width = 13, height = 8.5, units = "in", device = "pdf")

p = ggplot(data = fit, aes(time,temperature)) +
  geom_ribbon(aes(time, ymin = w_lower, ymax = w_upper), alpha = .3, fill = "#5b0982") +
  geom_ribbon(aes(time, ymin = a_lower, ymax = a_upper), alpha = .2, fill = "#7eb795") +
  geom_point(aes(color = f_est_source), size = 0.5) +
  geom_line(aes(time, w_fit), size = .3) +
  geom_line(aes(time, a_fit), size = .3) +
  geom_rug(data = filter(fit, f_error == 0), aes(time, temperature), sides = "b") +
  scale_color_manual(values = c("water" = "#2b6aff", "air" = "#ffc021", "uncertain" = "#45062e")) +
  geom_hline(yintercept = 0, size = .2, linetype = 3) +
  labs(color = "Estimated Thermal Source", x = "Month", y = expression("Temperature ("*degree*"C)")) +
  annotate("segment", x=min(fit$time), xend = max(fit$time), y=-Inf, yend=-Inf, size = .2) +
  ggthemes::theme_tufte() + 
  theme(legend.direction = "horizontal", legend.position = "top",
        strip.text = element_text(size=8),
        axis.text = element_text(size = 8)) + 
  scale_x_datetime(date_breaks = "3 month", date_labels = "%b") +
  guides(color = guide_legend(title.position = "top", title.hjust = 0.8)) +
  facet_wrap(~site, labeller = as_labeller(labels)) +
  geom_text(data = percent_error, aes(x = x_pos, y = y_pos, label = site), hjust = "left", size = 2.3)
ggsave(filename = "Error_Plot.pdf", path = "~/Documents/rTDataScrub/images", plot = p, width = 13, height = 8.5, units = "in", device = "pdf")
      #x_pos = min(.$time[lubridate::month(.$time)==2])-30

#Variance around mean water and ground temperature.
temp = temp %>% mutate(
  upper_w = mean_w + qt(.95,3)*sigma,
  lower_w = mean_w - qt(.95,3)*sigma) %>%
  select(-c(6:11))
```

Now we can apply our Hierarchical HMM to raw stream temperature data in the North Thompson. Something to consider and possibly include in our model is a random effect of A and alpha by year to adjust for inter-annual changes.

```{r Thompson Watershed Hierarchical HMM}
#Read in climate data and summarize by year.
df_inits = read_rds("./Data/thompson_air_inits.rds") %>%
  group_by(site) %>% summarise(air_mean = mean(air_mean), air_A = mean(air_A)/2)

#Read in water temperature data and remove site 102 as it is lake temperature.
df_T = read_rds("./Data/thompson_water.rds") %>% filter(site != 103)

#Limit sites for testing.
samp = sample(x = unique(df_inits$site), size = 20)
df_T = filter(df_T, site %in% samp)
df_inits = filter(df_inits, site %in% samp)

#Create a reference table to add new continuous site ID values to the water temperature data. 
ref = df_T %>% select(site) %>% distinct() %>% mutate(new_id = c(1:n()))

#Summarize the water temperature data to the daily level, 
# add new site ID, numer the observations continuously (i.e., d) in each site, and
# add the number of days in a cycle for each year.
df_dT = df_T %>% mutate(year = lubridate::year(date), 
                        day = lubridate::floor_date(date, unit = "day"), 
                        doy = lubridate::yday(date)) %>%
  group_by(site, year, day, doy) %>% summarise(temperature = mean(temperature)) %>% 
  left_join(., ref) %>% group_by(site) %>% mutate(d = (day-min(day))/lubridate::ddays(1)+1) %>% 
  group_by(site, year) %>% mutate(n_cycle = n_init(day))

#Add the climate inits with estimates of tau.
df_inits = df_dT %>% group_by(site) %>% 
  summarise(tau = tau_init(day)) %>%
  left_join(df_inits,.) %>% filter(!is.na(tau))

#Gather initial values.
inits = create_inits(air_A = df_inits$air_A, air_alpha = df_inits$air_mean, 
                     n_sites = length(unique(df_inits$site)), chains = 4, K = 2)

#Compile and run model.
compile = stan_model("./stan/04_HMM_GWA.stan")
mod = sampling(compile, data= list(N = length(df_dT$temperature),
                                 S = length(unique(df_dT$site)),
                                 site = df_dT$new_id,
                                 K = 2,
                                 y = round(df_dT$temperature,2),
                                 d = df_dT$d,
                                 tau = df_inits$tau,
                                 n = df_dT$n_cycle,
                                 air_A = inits[[1]]$A[,2],
                                 air_mean = inits[[1]]$alpha_air,
                                 water_A = inits[[1]]$A[,1],
                                 water_mean = inits[[1]]$alpha_water,
                                 prior = 1),
               pars = c("b_alpha_w","m_alpha_w",
                        "alpha_a","alpha_w","A","tau_est","sp_n","snow",
                        "alpha_tk","gamma"),
               init = inits, iter = 100, chains = 4, thin = 3,
               control = list(adapt_delta = .9, max_treedepth = 12),
               save_warmup = F, sample_file = "./stan/Mod_Results/04_HMM_GWA_Samples.csv")


#Read in model.
mod = read_rds(path = "./stan/Mod_Results/GWA_250_obs_mod.rds")
#mod = read_rds(path = "./stan/Mod_Results/GWA_1000_obs_mod.rds")

#---- Gather & Organize Coefficients ----#
cf1 = broom::tidy(mod, pars = c("A","tau_est"), "median") %>%
  select(-std.error) %>% 
  mutate(
    new_id = as.numeric(stringr::str_extract_all(string = term, pattern = "\\d+",simplify = T)[,1]),
    model = as.numeric(stringr::str_extract_all(string = term, pattern = "\\d+",simplify = T)[,2]),
    coef = stringr::str_extract_all(term, "\\w+", simplify = T)[,1]
  ) %>% 
  select(-term)

cf2 = broom::tidy(mod, pars = c("alpha_a","alpha_w"), "median") %>%
  select(-std.error) %>% 
  mutate(new_id = as.numeric(stringr::str_extract_all(string = term, pattern = "\\d+(?=\\])",simplify = T)),
         model = c(rep(2,101),rep(1,101)),
         coef = stringr::str_extract_all(term, "\\w+", simplify = T)[,1]) %>% 
  select(-term)

cf = rbind(cf1,cf2) %>% spread(key = coef, value = estimate)

#---- Organize Site Coef. Estimates Priors ----#
global =data.frame(new_id = c(cf[cf$model==1,"new_id"],cf[cf$model==2,"new_id"]),
                   air = c(cf[cf$model==2,c("alpha_a")],cf[cf$model==2,c("A")]),
                   water = c(cf[cf$model==1,c("alpha_w")],cf[cf$model==1,c("A")]),
                   parameter = c(rep("alpha",101),rep("A",101)),
                   air_prior = c(inits[[1]]$alpha_air,inits[[1]]$A[,2]),
                   water_prior = c(inits[[1]]$alpha_water,inits[[1]]$A[,1]))

#---- Gather and Spread Global Parameter Estimates ----#
global_pa = rstan::extract(mod, pars = c("m_alpha_w","b_alpha_w"))
global_pA = rstan::extract(mod, pars = "A")
#---- End Gather Site Coefficients ----#


#---- Fit and Plot Global Models ----#
air = c(seq(min(global[global$parameter=="alpha","air"]),
                  max(global[global$parameter=="alpha","air"]), by = 0.1))
fit = data.frame(t(sapply(air, FUN = function(x){
  quantile(exp(global_pa$b_alpha_w + global_pa$m_alpha_w * x), probs = c(0.025,.25,0.5,.75,.975))
})))
fit = fit %>% rename(lower = X2.5., lower_mid = X25., fit = X50., upper_mid = X75., upper = X97.5.) %>% mutate(air = air)

fit_A = data.frame(t(apply(global_pA$A, 2, function(x){
  quantile(x[,1], probs = c(0.025,.25,0.5,.75,.975))
})))
fit_A = fit_A %>% rename(lower = X2.5., lower_mid = X25., fit = X50., upper_mid = X75., upper = X97.5.) %>% 
  mutate(water = global[global$parameter == "alpha","water"])


#---- Plot Alpha_a vs. Alpha_a ----#
gp1 = ggplot() +
  geom_ribbon(data = fit, aes(x = air, ymin = lower, ymax = upper), alpha = 0.08) +
  geom_ribbon(data = fit, aes(x = air, ymin = lower_mid, ymax = upper_mid), alpha = 0.05) +
  #geom_line(data = global %>% filter(parameter == "alpha"),
  #           aes(air_prior, water_prior), color = "blue", alpha = .5) +
  geom_point(data = global %>% filter(parameter == "alpha", water < 10), aes(air, water), 
             col = "#45062e", shape = 19, size = .8) +
  geom_line(data = fit, aes(air, fit), linetype = 2, size = .3) +
  ggthemes::theme_tufte() +
  theme(strip.text = element_text(size=10),
        axis.text = element_text(size = 8), 
        axis.title = element_text(size = 9)) +
  labs(x = expression("Mean Annual Air Temperature ("*degree*"C)"), 
       y = expression("Mean Annual Water Temperature ("*degree*"C)"))

#---- Plot Alpha_w vs. A_w ----#
gp2 = ggplot(data = fit_A %>% filter(water<10)) +
  geom_errorbar(aes(x = water, ymax=upper, ymin=lower), linetype = 1, size = .1, alpha = .3) +
  geom_errorbar(aes(x = water, ymax=upper_mid, ymin=lower_mid), linetype = 1, size = .3, alpha = .5) +
  geom_point(aes(water,fit),col = "#45062e", shape = 19, size = .8)+
  geom_abline(slope = 1, intercept = 0, linetype = 2, size = .3) +
  ggthemes::theme_tufte() +
  theme(strip.text = element_text(size=10),
        axis.text = element_text(size = 8), 
        axis.title = element_text(size = 9)) +
  labs(x = expression("Mean Annual Water Temperature ("*degree*"C)"), 
       y = expression("Annual Water Temperature Amplitude ("*degree*"C)"))

p = gridExtra::grid.arrange(gp1, gp2, layout_matrix = matrix(data = c(1,2), nrow = 1, ncol = 2))
ggsave(filename = "Global_Obs.pdf", path = "~/Documents/rTDataScrub/images", plot = p, width = 7.5, height = 3.5, units = "in", device = "pdf")
#---- End Fit and Plot Global Models ----#


#---- Fit Individual Site Models ----#

#Read in air temperature data and bind to water temperature data
air_obs = read_rds("./Data/thompson_air.rds") %>% group_by(place, date) %>% 
  summarise(air_temperature = mean(mean_temp_c, na.rm = T))
air_stream = read_csv("./Data/stream_to_air_geo.csv") %>% select(site, air_site) %>% distinct()
air_stream$air_site = toupper(air_stream$air_site)
df_dT = left_join(df_dT,air_stream, by = "site")
df_dT$day = ymd(df_dT$day)
df_dT = left_join(df_dT,air_obs, by = c("air_site"="place","day"="date"))

#Get state probability estimates and add to observed temperature dataframe.
xi_est = broom::tidyMCMC(mod, pars = "gamma", estimate.method = "median", conf.int = F)
#Extract row number of each state matrix linked to each observation.
day = as.numeric(unlist(stringr::str_extract_all(string = xi_est$term, pattern = "\\d+(?=,)")))
#Extract model type
model = unlist(apply(xi_est, 1, function(x){
  if(grepl(x = x[1],  pattern = "\\w+\\[\\d+,1\\]")) "air"
  else if(grepl(x = x[1],  pattern = "\\w+\\[\\d+,2\\]")) "water"
}))
df_dT = xi_est %>% mutate(model,day) %>% select(-term, -std.error) %>% 
  spread(data = ., key = model, value = estimate) %>% select(-day) %>% 
  bind_cols(df_dT,.)

#Create full date range.
dates_full = data.frame(day = seq.Date(from = min(as.Date(df_dT$day)), to = max(as.Date(df_dT$day)), by = "day")) 

#Incorporate full range of dates into each site for fitting and plotting.
df_dT = df_dT %>% group_by(site) %>% do({
  temp = left_join(dates_full,.,by="day")
  day_one = temp[temp$d==1 & !is.na(temp$d),"day"]
  temp$d = as.numeric((temp$day - day_one) + 1)
  temp$year = year(temp$day)
  temp$site = unique(.$site)
  temp$doy = yday(temp$day)
  temp$new_id = unique(.$new_id)
  temp
})

#Function for fitting full bayes site models
fit_bayes = function(df, mod, source = "water"){
  df_dT %>% group_by(new_id) %>% do({
    site = unique(.$new_id)
    if(source == "water"){
      alpha = rstan::extract(mod, "alpha_w")[[1]]
      A = rstan::extract(mod, "A")[[1]][,,1]
      tau = rstan::extract(mod, "tau_est")[[1]][,,2]
    } else {
      alpha = rstan::extract(mod, "alpha_a")[[1]]
      A = rstan::extract(mod, "A")[[1]][,,2]
      tau = rstan::extract(mod, "tau_est")[[1]][,,1]
    }
    data.frame(t(sapply(.$d, FUN = function(x){
    quantile(alpha[,site] + A[,site]*cos(2*pi*x/365 + tau[,site]*pi), probs = c(0.025,.25,0.5,.75,.975))
  }))) %>% rename(lower = X2.5., lower_mid = X25., fit = X50., upper_mid = X75., upper = X97.5.)
  }) %>% bind_cols()
}
#Gather water and air temperature estimates.
water = fit_bayes(df_dT, mod)
air = fit_bayes(df_dT, mod, "air")
#Rename columns
names(water) = paste("water",names(water),sep = "_")
names(air) = paste("air",names(air),sep = "_")
#Combine data and fits
df = bind_cols(df_dT, water, air)

#Sample 10 sites and plot
s = c(49,65,54,39,1,80,87,93,100,74)
x_ext = range(df_dT$day)
p_df = df %>% filter(new_id %in% s)
label = p_df %>% select(new_id, site) %>% distinct()
p = ggplot(data = p_df) + 
  geom_point(aes(day, air_temperature),color = "red", alpha = .1, shape = 1, size = .3) +
  geom_ribbon(aes(x=day,ymin=air_lower,ymax=air_upper), alpha = .1, fill = "#7eb795") +
  geom_ribbon(aes(x=day,ymin=air_lower_mid,ymax=air_upper_mid), alpha = .3, fill = "#7eb795") +
  geom_ribbon(aes(x=day,ymin=water_lower,ymax=water_upper), alpha = .1, fill = "#5b0982") +
  geom_ribbon(aes(x=day,ymin=water_lower_mid,ymax=water_upper_mid), alpha = .3, fill = "#5b0982") +
  geom_point(aes(day, temperature, color = water), shape = 19, size = .3) +
  geom_hline(yintercept = 0, size = .2, linetype = 2) +
  annotate("segment", x=x_ext[1], xend = x_ext[2], y=-Inf, yend=-Inf, size = .2) +
  viridis::scale_color_viridis(direction = -1) +
  ggthemes::theme_tufte() +
  scale_x_date(date_breaks = "6 month", date_labels = "%y-%m") +
  labs(color ="Probability Water", x = "Year-Month", y = expression("Temperature ("*degree*"C)")) +
  theme(legend.direction = "horizontal", legend.position = "top", 
        legend.key.width = unit(3,"cm") ,
        legend.key.height = unit(.20,"cm"),
        strip.background = element_blank(),
        strip.text.x = element_blank()) +
  guides(colour = guide_colourbar(title.position="top")) +
  ylim(-25,25) +
  facet_wrap(nrow = 5, ncol = 2, facets = ~new_id) +
  geom_text(data = label, aes(x = x_ext[1], y = 23, label = site), hjust = "left", size = 2.3)
ggsave(filename = "Probs_Obs.pdf", path = "~/Documents/rTDataScrub/images", plot = p, width = 13, height = 8.5, units = "in", device = "pdf")

p_full = gridExtra::grid.arrange(p, p_single[[1]], p_single[[2]], p_single[[3]], 
                        layout_matrix = matrix(data = c(rep(1,10),2,3,3,4,4), nrow = 5, ncol = 3))
ggsave(filename = "Probs_Obs_Full.pdf", path = "~/Documents/rTDataScrub/images", plot = p_full, width = 13, height = 8.5, units = "in", device = "pdf")

```

After much tinkering we have chosen to linearize the global model described in the water only random effect model (i.e.,"water_rand.stan"). The model describing the steapness of the relationship seemed much too sensative, biasing mean water temperature estimates in the lower exponential part of the sigmoidal curve. We also included an amplitude global model that is approximately linear with the mean water temperature estimates. This model works for northern climate locations but I suspect will fail as we get closer to the equator where water temperature never nears 0ºC but rather are upper bound. This aspect of the model will be left for future development at this time. I've also discovered the importance of narrow priors on air and ground models and looser priors on water model parameters. By doing this we put the focus on estimating water parameters and less weight on partially known values such as air parameters. We expect that the data this model receives will mostly be water with limited air and often no ground temperature data. As such we want to make sure the data are primarily being used to inform the water model and less so the ground and air models.

I believe that since the data are generated under a logistic curve and the model linearizes using a log transformation, it becomes difficult to not have bias in the global model where lower mean annual water temperature data is over estimated while larger values are under-estimated. How does one allow the fit of the data take priority over fitting the global model? 




## Notes on Development

#### Generated Quantities Model Error
Sometimes when smoothing the data, the logbeta values are very small which leads to underflow and zeros in the beta/alpha_tk estimates. This leads to all zeros in the loggamma estimate and nonsense in the gamma estimate. For now I've just asked the model to print when this occurs. It may be a result of poorly developed models that have sense been remedied.
Example: {
t: 2191 log gamma: [0,0,0] beta: [0,1,4.26337e-30] alpha_tk: [1,0,0] logbeta: [-26002.6,-16174.2,-16241.8]
t: 2191 log gamma: [0,0,0] beta: [0,1,4.26337e-30] alpha_tk: [1,0,0] logbeta: [-26002.6,-16174.2,-16241.8]
t: 2191 log gamma: [0,0,0] beta: [0,1,4.26337e-30] alpha_tk: [1,0,0] logbeta: [-26002.6,-16174.2,-16241.8]
}

#### Amplitude Global Model
An amplitdue global model would be related to mean annual temperature in some way. Mean annual temperature would have a lower bound (0ºC) and an upper bound (~27ºC). Amplitude would probably increase linearly untill some inflection point midway between the bounds. Thus the amplitude would equal the distance between the mean annual temperature and the lower bound until the mean annual temperature increases to the point where the distance between the mean annual temperature and upper bound is less than the distance between the mean annual temperature and the lower bound.

            |2*(alpha_water-w_low)    : alpha_water-w_low < alpha_max-alpha_water
amplitude = |
            |2*(alpha_max-alpha_water): alpha_water-w_low > alpha_max-alpha_water

#### Mean water temperature global model
We need a global model that describes how air and water temperature are loosely related to help the model find a fit and limit the data to physically reasonable boundaries. I propose a model where water temperature follows air temperature, often laging below air temperature but asymptoting at 0 and ~27ºC. This model is the same as a logistic curve where the parameters are related to temperature. In this model it is important to remember that air estimates will be coming from models that already account for latitude, elevation and distance to large water water bodies. Therefore, we can assume these variables are accounted for when estimating water temperature from air temperature. By strengthening priors on the air parameters we can direct change to the water temperature part of the model. This will correct the influence between what is known prior to the fit (partial understanding of air) and what is largely unknown (water parameters).

#### By hand corrections.
Site 17 might need extra attention as it is the site with potential ground influence.
Site 79ish has some odd cold temperatures in the summer.

#### Flexible cosine model Idea

- This is likely just another form of a moving average model upon reflection. Once the data are clean, a MA model would be useful for filling gaps in data.

To make the water cosine model more flexible would be to adjust the d-parameter by the error in the observed data. In this way we can slow down or excelerate the curves progression over time but retain some rigidity to the model so it wont accomodate all data like a traditional MA model. Basically, we'd...
  1. Calculate the difference between the observed and the mean err = (obs-mea).
  2. Divide the error by the instantanious rate (i.e., derivative, A\*-sin(x)) d_adj = err/rate.
  3. Add the result in d_adj to the current d to create d in the next time step.
I'm not sure this solves the flexibility problem. I'm worried that when fitting the model the alpha and A parameters will just expand to encompass all the data and then use this rate adjustment to account for errors in the model.

```{r Flexible Cosine}
site = df_dT %>% filter(site == 49)
site$mean = 7.4 + 7.7*cos(2*pi*site$d/site$n_cycle + 0.07962798 *pi)

a = 7.4; A = 7.7
fin = vector(mode = "numeric", length = length(site$mean))
for(i in site$d){
  #browser()
  if(i == 1){
    est = a+A*cos(2*pi*i/365 + 0.07962798 *pi)
    d = 1
  } else est = a+A*cos(2*pi*d/365+ 0.07962798 *pi)
  err = site$temperature[i] - est
  rate = -sin(2*pi*d/365)
  if(i == 1) d = i + rate*err
  else d = d + err/rate
  fin[i] = est
}
site$fin = fin
ggplot(site, aes(day, temperature)) + geom_point() + geom_line(aes(day,mean),col = "blue") + 
  geom_line(aes(day, fin),col = "red")

```

#### Post Processing Idea
After a mean and amplitude are identified across sites we should be able to normalize the data by the mean and then ask by day across sites if any data points stand out away from the group. Data points that are in the tails of a say a broad t-distribution could be given a probability that down weights the liklihood of being water data. Also, if data across sites are commonly beyond the seasonal cosine curve at some point in the year, then we can improve their liklihood of being water.
